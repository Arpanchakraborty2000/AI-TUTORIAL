{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "444276f1ac872a09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:00:49.963368Z",
     "start_time": "2025-11-12T14:00:44.210898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\r\n",
      "  Downloading pandas-2.3.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (91 kB)\r\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from pandas) (2.3.3)\r\n",
      "Collecting python-dateutil>=2.8.2 (from pandas)\r\n",
      "  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\r\n",
      "Collecting pytz>=2020.1 (from pandas)\r\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "Collecting tzdata>=2022.7 (from pandas)\r\n",
      "  Using cached tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas)\r\n",
      "  Using cached six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Downloading pandas-2.3.3-cp313-cp313-macosx_11_0_arm64.whl (10.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m10.7/10.7 MB\u001B[0m \u001B[31m5.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m\r\n",
      "\u001B[?25hUsing cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\r\n",
      "Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\r\n",
      "Using cached six-1.17.0-py2.py3-none-any.whl (11 kB)\r\n",
      "Using cached tzdata-2025.2-py2.py3-none-any.whl (347 kB)\r\n",
      "Installing collected packages: pytz, tzdata, six, python-dateutil, pandas\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5/5\u001B[0m [pandas]2m4/5\u001B[0m [pandas]dateutil]\r\n",
      "\u001B[1A\u001B[2KSuccessfully installed pandas-2.3.3 python-dateutil-2.9.0.post0 pytz-2025.2 six-1.17.0 tzdata-2025.2\r\n"
     ]
    }
   ],
   "source": [
    "from operator import index\n",
    "!pip install pandas\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "990c93100614eeb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:04:04.151577Z",
     "start_time": "2025-11-12T14:04:04.148345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series : \n",
      " 0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "dtype: int64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data=[1,2,3,4,5]\n",
    "series=pd.Series(data)\n",
    "print(\"Series : \\n\",series)\n",
    "print(type(series))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0bd09da364a386b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:05:40.177556Z",
     "start_time": "2025-11-12T14:05:40.173436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series : \n",
      " a    1\n",
      "b    2\n",
      "c    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## create a series from dictionary\n",
    "\n",
    "data={'a':1,'b':2,'c':3}\n",
    "series=pd.Series(data)\n",
    "print(\"Series : \\n\",series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f59e83de3d28b553",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:13:57.058800Z",
     "start_time": "2025-11-12T14:13:57.049605Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "a    10\n",
       "b    20\n",
       "c    30\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=[10,20,30]\n",
    "index=['a','b','c']\n",
    "\n",
    "pd.Series(data,index=index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4b488b38ff4950c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:21:59.917985Z",
     "start_time": "2025-11-12T14:21:59.913438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age       City\n",
      "0  Arpan   20  Bangalore\n",
      "1  Abhik   30   New York\n",
      "2   Jack   40  Hyderabad\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "## Dataframe\n",
    "## create a data frame from dictionary of list\n",
    "\n",
    "data={\n",
    "    'Name':['Arpan','Abhik','Jack'],\n",
    "    'Age':[20,30,40],\n",
    "    'City':['Bangalore','New York','Hyderabad']\n",
    "}\n",
    "df=pd.DataFrame(data)\n",
    "print(df)\n",
    "print(type(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d90e801dc0308fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:22:59.840933Z",
     "start_time": "2025-11-12T14:22:59.836745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Arpan', 20, 'Bangalore'],\n",
       "       ['Abhik', 30, 'New York'],\n",
       "       ['Jack', 40, 'Hyderabad']], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "85af6028f59c6e27",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:36:01.906271Z",
     "start_time": "2025-11-12T14:36:01.900975Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Name  Age       City\n",
      "0  Arpan   32  Bangalore\n",
      "1  Baban   32  Bangalore\n",
      "2  Abhik   32  Bangalore\n",
      "3  Soham   32  Bangalore\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# create a dat frame list of dictionary\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "    {'Name':'Arpan','Age':32,'City':'Bangalore'},\n",
    "    {'Name':'Baban','Age':32,'City':'Bangalore'},\n",
    "    {'Name':'Abhik','Age':32,'City':'Bangalore'},\n",
    "    {'Name':'Soham','Age':32,'City':'Bangalore'}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(df)\n",
    "print(type(df))\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "98257960b0686583",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:45:07.320073Z",
     "start_time": "2025-11-12T14:45:07.310071Z"
    }
   },
   "source": [
    "df=pd.read_csv('MOCK_DATA.csv')\n",
    "print(df.head(100))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     id first_name   last_name                      email      gender  \\\n",
      "0     1      Dicky     Penrose     dpenrose0@blogspot.com        Male   \n",
      "1     2       Elsy      Bailie     ebailie1@reference.com      Female   \n",
      "2     3     Ulrike  Banaszczyk    ubanaszczyk2@google.com      Female   \n",
      "3     4      Davin   Hunnicutt         dhunnicutt3@w3.org        Male   \n",
      "4     5      Efrem       Dorro       edorro4@vkontakte.ru        Male   \n",
      "..  ...        ...         ...                        ...         ...   \n",
      "95   96    Mallory        Meco      mmeco2n@indiegogo.com  Polygender   \n",
      "96   97       Lyle    Jouandet       ljouandet2o@1688.com        Male   \n",
      "97   98     Adrian    O'Cannan       aocannan2p@about.com        Male   \n",
      "98   99      Abbie    Playfair  aplayfair2q@discovery.com        Male   \n",
      "99  100     Cullie    Mallison       cmallison2r@noaa.gov        Male   \n",
      "\n",
      "         ip_address  \n",
      "0     225.33.152.55  \n",
      "1     224.12.11.111  \n",
      "2    155.176.207.42  \n",
      "3    200.31.160.192  \n",
      "4      3.165.149.93  \n",
      "..              ...  \n",
      "95  245.184.187.159  \n",
      "96    35.30.127.251  \n",
      "97    48.142.181.63  \n",
      "98   121.68.168.241  \n",
      "99   22.213.137.238  \n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T14:46:01.657125Z",
     "start_time": "2025-11-12T14:46:01.652368Z"
    }
   },
   "cell_type": "code",
   "source": "print(df.tail(100))",
   "id": "d6539db5ddb023f7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       id first_name   last_name                    email  gender  \\\n",
      "900   901    Bethany      Leport    bleportp0@myspace.com  Female   \n",
      "901   902        Bud  Pillington   bpillingtonp1@gmpg.org    Male   \n",
      "902   903      Tyler     Hateley  thateleyp2@redcross.org    Male   \n",
      "903   904    Deloria     Capenor    dcapenorp3@reddit.com  Female   \n",
      "904   905    Harwell       Ashbe         hashbep4@aol.com    Male   \n",
      "..    ...        ...         ...                      ...     ...   \n",
      "995   996      Karna       Elias  keliasrn@cloudflare.com  Female   \n",
      "996   997     Shaine       Hanna     shannaro@godaddy.com  Female   \n",
      "997   998     Shanon   Ivanyutin   sivanyutinrp@adobe.com  Female   \n",
      "998   999     Coriss      Tesche     ctescherq@zimbio.com  Female   \n",
      "999  1000    Melamie       Kirsz        mkirszrr@yale.edu  Female   \n",
      "\n",
      "          ip_address  \n",
      "900   131.177.244.96  \n",
      "901  130.139.226.224  \n",
      "902     99.77.188.19  \n",
      "903  242.244.145.198  \n",
      "904   86.218.138.128  \n",
      "..               ...  \n",
      "995    214.167.34.18  \n",
      "996    143.198.38.32  \n",
      "997   158.94.206.198  \n",
      "998   39.138.141.146  \n",
      "999   78.182.205.216  \n",
      "\n",
      "[100 rows x 6 columns]\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:40:47.387431Z",
     "start_time": "2025-11-12T19:40:47.380927Z"
    }
   },
   "cell_type": "code",
   "source": "data",
   "id": "404ad1ce0de06264",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Name': 'Arpan', 'Age': 32, 'City': 'Bangalore'},\n",
       " {'Name': 'Baban', 'Age': 32, 'City': 'Bangalore'},\n",
       " {'Name': 'Abhik', 'Age': 32, 'City': 'Bangalore'},\n",
       " {'Name': 'Soham', 'Age': 32, 'City': 'Bangalore'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:47:04.092063Z",
     "start_time": "2025-11-12T19:47:04.085118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Adding new column\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "data = [\n",
    "    {'Name':'Arpan','Age':32,'City':'Bangalore'},\n",
    "    {'Name':'Baban','Age':28,'City':'Kolkata'},\n",
    "    {'Name':'Abhik','Age':30,'City':'Delhi'},\n",
    "    {'Name':'Soham','Age':25,'City':'Mumbai'}\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Before:\\n\", df)\n",
    "\n",
    "# Add new column 'Salary' with same value\n",
    "df[\"Salary\"] = [50000,60000,70000,80000]\n",
    "\n",
    "print(\"\\nAfter:\\n\", df)\n",
    "\n"
   ],
   "id": "49a94d1831bc3af4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "     Name  Age       City\n",
      "0  Arpan   32  Bangalore\n",
      "1  Baban   28    Kolkata\n",
      "2  Abhik   30      Delhi\n",
      "3  Soham   25     Mumbai\n",
      "\n",
      "After:\n",
      "     Name  Age       City  Salary\n",
      "0  Arpan   32  Bangalore   50000\n",
      "1  Baban   28    Kolkata   60000\n",
      "2  Abhik   30      Delhi   70000\n",
      "3  Soham   25     Mumbai   80000\n"
     ]
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-12T19:49:01.578325Z",
     "start_time": "2025-11-12T19:49:01.549026Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df.drop('Salary', axis=1, inplace=True)\n",
    "print(\"\\nAfter:\\n\", df)"
   ],
   "id": "3baa25d49110b058",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Salary'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[43], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mdf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mSalary\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mAfter:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m, df)\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:5588\u001B[0m, in \u001B[0;36mDataFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   5440\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21mdrop\u001B[39m(\n\u001B[1;32m   5441\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   5442\u001B[0m     labels: IndexLabel \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5449\u001B[0m     errors: IgnoreRaise \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   5450\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   5451\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   5452\u001B[0m \u001B[38;5;124;03m    Drop specified labels from rows or columns.\u001B[39;00m\n\u001B[1;32m   5453\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5586\u001B[0m \u001B[38;5;124;03m            weight  1.0     0.8\u001B[39;00m\n\u001B[1;32m   5587\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 5588\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   5589\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlabels\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5590\u001B[0m \u001B[43m        \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5591\u001B[0m \u001B[43m        \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5592\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5593\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5594\u001B[0m \u001B[43m        \u001B[49m\u001B[43minplace\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minplace\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5595\u001B[0m \u001B[43m        \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   5596\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:4807\u001B[0m, in \u001B[0;36mNDFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   4805\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis, labels \u001B[38;5;129;01min\u001B[39;00m axes\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m   4806\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 4807\u001B[0m         obj \u001B[38;5;241m=\u001B[39m \u001B[43mobj\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_drop_axis\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlevel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlevel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4809\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[1;32m   4810\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_inplace(obj)\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:4849\u001B[0m, in \u001B[0;36mNDFrame._drop_axis\u001B[0;34m(self, labels, axis, level, errors, only_slice)\u001B[0m\n\u001B[1;32m   4847\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mdrop(labels, level\u001B[38;5;241m=\u001B[39mlevel, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[1;32m   4848\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 4849\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m \u001B[43maxis\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdrop\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4850\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mget_indexer(new_axis)\n\u001B[1;32m   4852\u001B[0m \u001B[38;5;66;03m# Case for non-unique axis\u001B[39;00m\n\u001B[1;32m   4853\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:7136\u001B[0m, in \u001B[0;36mIndex.drop\u001B[0;34m(self, labels, errors)\u001B[0m\n\u001B[1;32m   7134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[1;32m   7135\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 7136\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabels[mask]\u001B[38;5;241m.\u001B[39mtolist()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found in axis\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   7137\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m indexer[\u001B[38;5;241m~\u001B[39mmask]\n\u001B[1;32m   7138\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete(indexer)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"['Salary'] not found in axis\""
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:30:15.243049Z",
     "start_time": "2025-11-19T18:30:15.222569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# install (run in your environment)\n",
    "# pip install transformers accelerate bitsandbytes peft datasets trl\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# 1) Load dataset (example: JSONL with {\"prompt\":..., \"response\":...})\n",
    "ds = load_dataset(\"json\", data_files={\"train\":\"train.jsonl\", \"validation\":\"val.jsonl\"})\n",
    "\n",
    "# 2) Tokenizer & model (use a quantized-compatible model)\n",
    "MODEL = \"meta-llama/Llama-2-7b-chat-hf\"  # example — ensure licensing\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=False)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    load_in_8bit=True,           # bitsandbytes quantization\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# 3) Prepare model for k-bit training and attach LoRA\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "lora_config = LoraConfig(\n",
    "    r=16, lora_alpha=32, target_modules=[\"q_proj\",\"v_proj\"], lora_dropout=0.05, bias=\"none\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# 4) Tokenize dataset (simple example)\n",
    "def tokenize(example):\n",
    "    prompt = example[\"prompt\"] + \"\\n\\n\" + example[\"response\"]\n",
    "    return tokenizer(prompt, truncation=True, max_length=1024)\n",
    "ds = ds.map(tokenize, batched=True)\n",
    "\n",
    "# 5) Training args & Trainer (simple)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora-finetuned\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=50,\n",
    "    save_total_limit=3,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=8,\n",
    "    optim=\"paged_adamw_32bit\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    ")\n",
    "trainer.train()\n",
    "# Save\n",
    "model.save_pretrained(\"./lora-finetuned\")\n",
    "tokenizer.save_pretrained(\"./lora-finetuned\")\n"
   ],
   "id": "7825a0058667cb46",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# install (run in your environment)\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# pip install transformers accelerate bitsandbytes peft datasets trl\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mdatasets\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m load_dataset\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpeft\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'datasets'"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:29:58.926252Z",
     "start_time": "2025-11-19T18:29:04.391771Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install datasets transformers accelerate bitsandbytes peft trl --upgrade\n",
    "\n"
   ],
   "id": "2c835fe899dfd668",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting datasets\r\n",
      "  Downloading datasets-4.4.1-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting transformers\r\n",
      "  Downloading transformers-4.57.1-py3-none-any.whl.metadata (43 kB)\r\n",
      "Collecting accelerate\r\n",
      "  Downloading accelerate-1.11.0-py3-none-any.whl.metadata (19 kB)\r\n",
      "Collecting bitsandbytes\r\n",
      "  Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\r\n",
      "Collecting peft\r\n",
      "  Downloading peft-0.18.0-py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting trl\r\n",
      "  Downloading trl-0.25.1-py3-none-any.whl.metadata (11 kB)\r\n",
      "Collecting filelock (from datasets)\r\n",
      "  Downloading filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from datasets) (2.3.3)\r\n",
      "Collecting pyarrow>=21.0.0 (from datasets)\r\n",
      "  Downloading pyarrow-22.0.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (3.2 kB)\r\n",
      "Collecting dill<0.4.1,>=0.3.0 (from datasets)\r\n",
      "  Downloading dill-0.4.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from datasets) (2.3.3)\r\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from datasets) (2.32.4)\r\n",
      "Collecting httpx<1.0.0 (from datasets)\r\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\r\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from datasets) (4.67.1)\r\n",
      "Collecting xxhash (from datasets)\r\n",
      "  Downloading xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\r\n",
      "Collecting multiprocess<0.70.19 (from datasets)\r\n",
      "  Downloading multiprocess-0.70.18-py313-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting fsspec<=2025.10.0,>=2023.1.0 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\r\n",
      "  Downloading fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting huggingface-hub<2.0,>=0.25.0 (from datasets)\r\n",
      "  Downloading huggingface_hub-1.1.4-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from datasets) (25.0)\r\n",
      "Collecting pyyaml>=5.1 (from datasets)\r\n",
      "  Downloading pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.4 kB)\r\n",
      "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\r\n",
      "  Downloading aiohttp-3.13.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (8.1 kB)\r\n",
      "Collecting anyio (from httpx<1.0.0->datasets)\r\n",
      "  Using cached anyio-4.11.0-py3-none-any.whl.metadata (4.1 kB)\r\n",
      "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (2025.8.3)\r\n",
      "Collecting httpcore==1.* (from httpx<1.0.0->datasets)\r\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\r\n",
      "Requirement already satisfied: idna in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from httpx<1.0.0->datasets) (3.7)\r\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1.0.0->datasets)\r\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\r\n",
      "Collecting hf-xet<2.0.0,>=1.2.0 (from huggingface-hub<2.0,>=0.25.0->datasets)\r\n",
      "  Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl.metadata (4.9 kB)\r\n",
      "Requirement already satisfied: shellingham in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.5.0)\r\n",
      "Collecting typer-slim (from huggingface-hub<2.0,>=0.25.0->datasets)\r\n",
      "  Downloading typer_slim-0.20.0-py3-none-any.whl.metadata (16 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.12.2)\r\n",
      "Collecting huggingface-hub<2.0,>=0.25.0 (from datasets)\r\n",
      "  Downloading huggingface_hub-0.36.0-py3-none-any.whl.metadata (14 kB)\r\n",
      "Collecting regex!=2019.12.17 (from transformers)\r\n",
      "  Downloading regex-2025.11.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (40 kB)\r\n",
      "Collecting tokenizers<=0.23.0,>=0.22.0 (from transformers)\r\n",
      "  Downloading tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\r\n",
      "Collecting safetensors>=0.4.3 (from transformers)\r\n",
      "  Downloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl.metadata (4.1 kB)\r\n",
      "Collecting psutil (from accelerate)\r\n",
      "  Using cached psutil-7.1.3-cp36-abi3-macosx_11_0_arm64.whl.metadata (23 kB)\r\n",
      "Collecting torch>=2.0.0 (from accelerate)\r\n",
      "  Downloading torch-2.9.1-cp313-none-macosx_11_0_arm64.whl.metadata (30 kB)\r\n",
      "Collecting scipy (from bitsandbytes)\r\n",
      "  Downloading scipy-1.16.3-cp313-cp313-macosx_14_0_arm64.whl.metadata (62 kB)\r\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\r\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\r\n",
      "  Downloading aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\r\n",
      "Collecting attrs>=17.3.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\r\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\r\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\r\n",
      "  Downloading frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (20 kB)\r\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\r\n",
      "  Downloading multidict-6.7.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (5.3 kB)\r\n",
      "Collecting propcache>=0.2.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\r\n",
      "  Downloading propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (13 kB)\r\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.10.0,>=2023.1.0->datasets)\r\n",
      "  Downloading yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl.metadata (75 kB)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (3.3.2)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from requests>=2.32.2->datasets) (2.5.0)\r\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (72.1.0)\r\n",
      "Collecting sympy>=1.13.3 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\r\n",
      "Collecting networkx>=2.5.1 (from torch>=2.0.0->accelerate)\r\n",
      "  Downloading networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\r\n",
      "Collecting jinja2 (from torch>=2.0.0->accelerate)\r\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch>=2.0.0->accelerate)\r\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1.0.0->datasets)\r\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=2.0.0->accelerate)\r\n",
      "  Downloading markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.7 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from pandas->datasets) (2025.2)\r\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\r\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/homebrew/Caskroom/miniconda/base/lib/python3.13/site-packages (from typer-slim->huggingface-hub<2.0,>=0.25.0->datasets) (8.2.1)\r\n",
      "Downloading datasets-4.4.1-py3-none-any.whl (511 kB)\r\n",
      "Downloading dill-0.4.0-py3-none-any.whl (119 kB)\r\n",
      "Downloading fsspec-2025.10.0-py3-none-any.whl (200 kB)\r\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\r\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\r\n",
      "Downloading hf_xet-1.2.0-cp37-abi3-macosx_11_0_arm64.whl (2.7 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.7/2.7 MB\u001B[0m \u001B[31m9.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0mta \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading multiprocess-0.70.18-py313-none-any.whl (151 kB)\r\n",
      "Downloading transformers-4.57.1-py3-none-any.whl (12.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.0/12.0 MB\u001B[0m \u001B[31m11.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading huggingface_hub-0.36.0-py3-none-any.whl (566 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m566.1/566.1 kB\u001B[0m \u001B[31m9.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading tokenizers-0.22.1-cp39-abi3-macosx_11_0_arm64.whl (2.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.9/2.9 MB\u001B[0m \u001B[31m10.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading accelerate-1.11.0-py3-none-any.whl (375 kB)\r\n",
      "Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m105.0/105.0 MB\u001B[0m \u001B[31m10.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading peft-0.18.0-py3-none-any.whl (556 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m556.4/556.4 kB\u001B[0m \u001B[31m7.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading trl-0.25.1-py3-none-any.whl (465 kB)\r\n",
      "Downloading aiohttp-3.13.2-cp313-cp313-macosx_11_0_arm64.whl (489 kB)\r\n",
      "Downloading multidict-6.7.0-cp313-cp313-macosx_11_0_arm64.whl (43 kB)\r\n",
      "Downloading yarl-1.22.0-cp313-cp313-macosx_11_0_arm64.whl (93 kB)\r\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\r\n",
      "Downloading aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\r\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\r\n",
      "Downloading frozenlist-1.8.0-cp313-cp313-macosx_11_0_arm64.whl (49 kB)\r\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\r\n",
      "Downloading propcache-0.4.1-cp313-cp313-macosx_11_0_arm64.whl (46 kB)\r\n",
      "Downloading pyarrow-22.0.0-cp313-cp313-macosx_12_0_arm64.whl (34.2 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m34.2/34.2 MB\u001B[0m \u001B[31m9.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pyyaml-6.0.3-cp313-cp313-macosx_11_0_arm64.whl (173 kB)\r\n",
      "Downloading regex-2025.11.3-cp313-cp313-macosx_11_0_arm64.whl (288 kB)\r\n",
      "Downloading safetensors-0.7.0-cp38-abi3-macosx_11_0_arm64.whl (447 kB)\r\n",
      "Downloading torch-2.9.1-cp313-none-macosx_11_0_arm64.whl (74.5 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m74.5/74.5 MB\u001B[0m \u001B[31m10.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading networkx-3.5-py3-none-any.whl (2.0 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m9.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.3/6.3 MB\u001B[0m \u001B[31m11.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading mpmath-1.3.0-py3-none-any.whl (536 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m536.2/536.2 kB\u001B[0m \u001B[31m7.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hUsing cached anyio-4.11.0-py3-none-any.whl (109 kB)\r\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\r\n",
      "Downloading filelock-3.20.0-py3-none-any.whl (16 kB)\r\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\r\n",
      "Downloading markupsafe-3.0.3-cp313-cp313-macosx_11_0_arm64.whl (12 kB)\r\n",
      "Using cached psutil-7.1.3-cp36-abi3-macosx_11_0_arm64.whl (239 kB)\r\n",
      "Downloading scipy-1.16.3-cp313-cp313-macosx_14_0_arm64.whl (20.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m20.9/20.9 MB\u001B[0m \u001B[31m7.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0mm\r\n",
      "\u001B[?25hDownloading xxhash-3.6.0-cp313-cp313-macosx_11_0_arm64.whl (30 kB)\r\n",
      "Installing collected packages: mpmath, xxhash, sympy, sniffio, scipy, safetensors, regex, pyyaml, pyarrow, psutil, propcache, networkx, multidict, MarkupSafe, hf-xet, h11, fsspec, frozenlist, filelock, dill, attrs, aiohappyeyeballs, yarl, multiprocess, jinja2, huggingface-hub, httpcore, bitsandbytes, anyio, aiosignal, torch, tokenizers, httpx, aiohttp, transformers, accelerate, peft, datasets, trl\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m39/39\u001B[0m [trl]32m38/39\u001B[0m [trl]sets]ers]ub]\r\n",
      "\u001B[1A\u001B[2KSuccessfully installed MarkupSafe-3.0.3 accelerate-1.11.0 aiohappyeyeballs-2.6.1 aiohttp-3.13.2 aiosignal-1.4.0 anyio-4.11.0 attrs-25.4.0 bitsandbytes-0.42.0 datasets-4.4.1 dill-0.4.0 filelock-3.20.0 frozenlist-1.8.0 fsspec-2025.10.0 h11-0.16.0 hf-xet-1.2.0 httpcore-1.0.9 httpx-0.28.1 huggingface-hub-0.36.0 jinja2-3.1.6 mpmath-1.3.0 multidict-6.7.0 multiprocess-0.70.18 networkx-3.5 peft-0.18.0 propcache-0.4.1 psutil-7.1.3 pyarrow-22.0.0 pyyaml-6.0.3 regex-2025.11.3 safetensors-0.7.0 scipy-1.16.3 sniffio-1.3.1 sympy-1.14.0 tokenizers-0.22.1 torch-2.9.1 transformers-4.57.1 trl-0.25.1 xxhash-3.6.0 yarl-1.22.0\r\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "527c413c7ec99d33"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-19T18:35:00.781251Z",
     "start_time": "2025-11-19T18:35:00.746576Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# install (run in your environment)\n",
    "# pip install transformers accelerate bitsandbytes peft datasets trl\n",
    "\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "# 1) Load dataset (example: JSONL with {\"prompt\":..., \"response\":...})\n",
    "ds = load_dataset(\"json\", data_files={\"train\":\"train.jsonl\", \"validation\":\"val.jsonl\"})\n",
    "\n",
    "# 2) Tokenizer & model (use a quantized-compatible model)\n",
    "MODEL = \"meta-llama/Llama-2-7b-chat-hf\"  # example — ensure licensing\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=False)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL,\n",
    "    load_in_8bit=True,           # bitsandbytes quantization\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# 3) Prepare model for k-bit training and attach LoRA\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "lora_config = LoraConfig(\n",
    "    r=16, lora_alpha=32, target_modules=[\"q_proj\",\"v_proj\"], lora_dropout=0.05, bias=\"none\"\n",
    ")\n",
    "model = get_peft_model(model, lora_config)\n",
    "\n",
    "# 4) Tokenize dataset (simple example)\n",
    "def tokenize(example):\n",
    "    prompt = example[\"prompt\"] + \"\\n\\n\" + example[\"response\"]\n",
    "    return tokenizer(prompt, truncation=True, max_length=1024)\n",
    "ds = ds.map(tokenize, batched=True)\n",
    "\n",
    "# 5) Training args & Trainer (simple)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./lora-finetuned\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    logging_steps=50,\n",
    "    save_total_limit=3,\n",
    "    fp16=True,\n",
    "    gradient_accumulation_steps=8,\n",
    "    optim=\"paged_adamw_32bit\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    ")\n",
    "trainer.train()\n",
    "# Save\n",
    "model.save_pretrained(\"./lora-finetuned\")\n",
    "tokenizer.save_pretrained(\"./lora-finetuned\")\n",
    "\n",
    "\n"
   ],
   "id": "a8042b56c210771b",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'datasets'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[25], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# install (run in your environment)\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# pip install transformers accelerate bitsandbytes peft datasets trl\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mdatasets\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m load_dataset\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m AutoTokenizer, AutoModelForCausalLM\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01mpeft\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'datasets'"
     ]
    }
   ],
   "execution_count": 25
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
